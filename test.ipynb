{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6373b49-de5e-4130-b51d-2495815e4408",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/root/EDA_contrastive_learning/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5132c1b2-2d40-46a9-99a1-0b109cbe8fd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting neurokit2\n",
      "  Downloading neurokit2-0.2.10-py2.py3-none-any.whl (693 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.1/693.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Requirement already satisfied: pandas in /root/.clearml/venvs-builds/3.11/lib/python3.11/site-packages (from neurokit2) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /root/.clearml/venvs-builds/3.11/lib/python3.11/site-packages (from neurokit2) (1.6.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from neurokit2) (2.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from neurokit2) (2.31.0)\n",
      "Requirement already satisfied: scipy in /root/.clearml/venvs-builds/3.11/lib/python3.11/site-packages (from neurokit2) (1.14.1)\n",
      "Requirement already satisfied: matplotlib in /root/.clearml/venvs-builds/3.11/lib/python3.11/site-packages (from neurokit2) (3.9.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /root/.clearml/venvs-builds/3.11/lib/python3.11/site-packages (from scikit-learn>=1.0.0->neurokit2) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /root/.clearml/venvs-builds/3.11/lib/python3.11/site-packages (from scikit-learn>=1.0.0->neurokit2) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neurokit2) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /root/.clearml/venvs-builds/3.11/lib/python3.11/site-packages (from matplotlib->neurokit2) (11.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /root/.clearml/venvs-builds/3.11/lib/python3.11/site-packages (from matplotlib->neurokit2) (1.3.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /root/.clearml/venvs-builds/3.11/lib/python3.11/site-packages (from matplotlib->neurokit2) (4.55.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /root/.clearml/venvs-builds/3.11/lib/python3.11/site-packages (from matplotlib->neurokit2) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->neurokit2) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /root/.clearml/venvs-builds/3.11/lib/python3.11/site-packages (from matplotlib->neurokit2) (1.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neurokit2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/.clearml/venvs-builds/3.11/lib/python3.11/site-packages (from pandas->neurokit2) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/.clearml/venvs-builds/3.11/lib/python3.11/site-packages (from pandas->neurokit2) (2024.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->neurokit2) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->neurokit2) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->neurokit2) (1.26.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->neurokit2) (3.10)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->neurokit2) (1.16.0)\n",
      "Installing collected packages: neurokit2\n",
      "Successfully installed neurokit2-0.2.10\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install neurokit2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "100280d2-668a-4cbe-9952-09931405c6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 240, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h5py\n",
    "import os\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "def get_data(data_path='./'):\n",
    "    unlabeled_eda = []\n",
    "    labeled_eda = []\n",
    "    labels = []\n",
    "    for fn in glob(os.path.join(data_path, '*.h5')):\n",
    "        f = h5py.File(fn, 'r')\n",
    "        # print(fn, f['eda'].shape)\n",
    "        unlabeled_eda += f['eda_unlabel']\n",
    "        labeled_eda += f['eda']\n",
    "        labels += (np.array(f['label'])==2).astype(np.int32).tolist()\n",
    "        # print(f['label'])\n",
    "        break\n",
    "        # print(len(data))\n",
    "    return unlabeled_eda, labeled_eda, labels\n",
    "# data = np.concatenate(data, axis=1)\n",
    "u_data, l_data, labels = get_data()\n",
    "data = np.array(l_data)\n",
    "print(data.shape)\n",
    "plt.plot(data[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d96ceef-5a1a-45fc-acef-3af113222ce6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, ops\n",
    "from tensorflow.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_dataset(data_path='./', batch_size=64, test_size=0.2, seed=42):\n",
    "    unlabeled_eda = []\n",
    "    labeled_eda = []\n",
    "    labels = []\n",
    "    for fn in glob(os.path.join(data_path, '*.h5')):\n",
    "        f = h5py.File(fn, 'r')\n",
    "        unlabeled_eda += f['eda_unlabel']\n",
    "        labeled_eda += f['eda']\n",
    "        labels += (np.array(f['label'])==2).astype(np.int32).tolist()\n",
    "    # labels = list(range(len(labeled_eda)))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(labeled_eda, labels, test_size=test_size, random_state=seed)\n",
    "    unlabeled_train_ds = Dataset.from_tensor_slices(unlabeled_eda)\n",
    "    labeled_train_ds = Dataset.from_tensor_slices((X_train, y_train))\n",
    "    labeled_test_ds = Dataset.from_tensor_slices((X_test, y_test)) \\\n",
    "        .batch(batch_size) \\\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    unlabeled_ds_len, labeled_ds_len = unlabeled_train_ds.cardinality(), labeled_train_ds.cardinality()\n",
    "    steps_per_epoch = (unlabeled_ds_len + labeled_ds_len) // batch_size\n",
    "    unlabeled_bs = unlabeled_ds_len // steps_per_epoch\n",
    "    labeled_bs = labeled_ds_len // steps_per_epoch\n",
    "\n",
    "    train_ds = tf.data.Dataset.zip(\n",
    "        (unlabeled_train_ds.shuffle(buffer_size=10 * unlabeled_bs).batch(unlabeled_bs), \n",
    "         labeled_train_ds.shuffle(buffer_size=10 * labeled_bs).batch(labeled_bs))\n",
    "    ).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    \n",
    "    labeled_train_ds = labeled_train_ds.batch(batch_size) \\\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    return train_ds, labeled_train_ds, labeled_test_ds\n",
    "train_ds, labeled_train_ds, test_ds = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c4a83dba-5afd-45ae-9375-7eb2fd5666c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(data_path='./', batch_size=64, test_size=0.2, seed=42):\n",
    "    unlabeled_eda = []\n",
    "    labeled_eda = []\n",
    "    labels = []\n",
    "    for fn in glob(os.path.join(data_path, '*.h5')):\n",
    "        f = h5py.File(fn, 'r')\n",
    "        unlabeled_eda += f['eda_unlabel']\n",
    "        labeled_eda += f['eda']\n",
    "        labels += f['label']\n",
    "    # labels = list(range(len(labeled_eda)))\n",
    "    unlabeled_eda, labeled_eda = np.array(unlabeled_eda, np.float32), np.array(labeled_eda, np.float32)\n",
    "    labels = (np.array(labels)==2).astype(np.int32)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(labeled_eda, labels, test_size=test_size, random_state=seed)\n",
    "    unlabeled_train_ds = Dataset.from_tensor_slices(unlabeled_eda) \\\n",
    "        .batch(batch_size) \\\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    labeled_train_ds = Dataset.from_tensor_slices((X_train, y_train)) \\\n",
    "        .batch(batch_size) \\\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    labeled_test_ds = Dataset.from_tensor_slices((X_test, y_test)) \\\n",
    "        .batch(batch_size) \\\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    return unlabeled_train_ds, labeled_train_ds, labeled_test_ds\n",
    "unlabeled_train_ds, labeled_train_ds, test_ds = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a5046f06-b102-4af5-81ad-f1639c989d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(16, shape=(), dtype=int64)\n",
      "tf.Tensor(72, shape=(), dtype=int64)\n",
      "tf.Tensor(72, shape=(), dtype=int64)\n",
      "72 (240, 1)\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(labeled_train_ds.cardinality())\n",
    "print(Dataset.from_tensor_slices(labels).cardinality())\n",
    "print(Dataset.from_tensor_slices(l_data).cardinality())\n",
    "print(len(l_data), l_data[0].shape)\n",
    "print(type(l_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c3416e73-53c0-402c-8124-2c792f81bc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 240, 1)\n",
      "(64, 240, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class LowPassFilterDeterministic():\n",
    "    def __init__(self, data_freq=4, highcut_hz=0.05, **kwargs):\n",
    "        \"\"\"\n",
    "        Apply low pass filter to remove frequency bands >= highcut_hz\n",
    "        :param data_freq: frequency of data to apply filter to (e.g., 4Hz for EDA)\n",
    "        :param highcut_hz: lower bound on frequency bands to remove\n",
    "        \"\"\"\n",
    "        self.data_freq = data_freq\n",
    "        self.highcut_hz = highcut_hz\n",
    "        self.b, self.a = scipy.signal.butter(4, [highcut_hz], btype=\"lowpass\", output=\"ba\", fs=data_freq)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # print(x.shape)\n",
    "        segment_filtered = scipy.signal.filtfilt(self.b, self.a, x, axis=1)\n",
    "        return segment_filtered.astype(np.float32)\n",
    "\n",
    "\n",
    "class GaussianNoiseDeterministic:\n",
    "    def __init__(self, sigma_scale=0.1):\n",
    "        \"\"\"\n",
    "        :param sigma_scale: factor to use in computing sigma parameter for noise distribution\n",
    "            sigma = mean(abs(diff between signal & mean))) * sigma_scale\n",
    "        \"\"\"\n",
    "        self.sigma_scale = sigma_scale\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = np.squeeze(x, -1)\n",
    "        mean_power_diff = np.mean(np.abs(x - np.mean(x, axis=1, keepdims=True)),axis=1, keepdims=True)\n",
    "        noise_sigma = mean_power_diff * self.sigma_scale\n",
    "        noise = np.random.normal(scale=noise_sigma, size=x.shape)\n",
    "        # print((x + noise).shape)\n",
    "        return np.expand_dims(x + noise, -1).astype(np.float32)\n",
    "\n",
    "\n",
    "class GaussianNoiseStochastic:\n",
    "    def __init__(self, sigma_scale_min=0.0, sigma_scale_max=0.5):\n",
    "        \"\"\"\n",
    "        :param sigma_scale_min: min factor to use in computing sigma parameter for noise distribution\n",
    "        :param sigma_scale_max: max factor to use in computing sigma parameter for noise distribution\n",
    "            sample sigma_scale uniformly in [sigma_scale_min, sigma_scale_max)\n",
    "            sigma = mean(abs(diff between signal & mean))) * sigma_scale\n",
    "        \"\"\"\n",
    "        self.sigma_scale_min = sigma_scale_min\n",
    "        self.sigma_scale_max = sigma_scale_max\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # sample sigma scale\n",
    "        x = np.squeeze(x, -1)\n",
    "        sigma_scale = np.random.uniform(self.sigma_scale_min, self.sigma_scale_max, size=(x.shape[0],1))\n",
    "        # print(sigma_scale.shape)\n",
    "        mean_power_diff = np.mean(np.abs(x - np.mean(x, axis=1, keepdims=True)),axis=1, keepdims=True)\n",
    "        noise_sigma = mean_power_diff * sigma_scale\n",
    "        noise = np.random.normal(scale=noise_sigma, size=x.shape)\n",
    "        return np.expand_dims(x + noise, -1).astype(np.float32)\n",
    "\n",
    "\n",
    "def get_augment_func(augmenters):\n",
    "    def augment(x):\n",
    "        for aug in augmenters:\n",
    "            if (tf.random.uniform(maxval=1, shape=[1])>0.5):\n",
    "                x = tf.numpy_function(aug, [x], [tf.float32])[0]\n",
    "        return x\n",
    "    return augment\n",
    "    \n",
    "augmenters = [\n",
    "    GaussianNoiseStochastic(0.1),\n",
    "    LowPassFilterDeterministic(),\n",
    " ]\n",
    "for u in unlabeled_train_ds.map(get_augment_func(augmenters)).take(1):\n",
    "    print(u.shape)\n",
    "    plt.plot(u[0])\n",
    "for u in unlabeled_train_ds.take(1):\n",
    "    print(u.shape)\n",
    "    plt.plot(u[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa424b0b-1069-414e-b211-6d35e8b3dde6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def build_encoder():\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            layers.Input((240,1)),\n",
    "            layers.Conv1D(4, kernel_size=7, strides=1),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu'),\n",
    "            layers.MaxPool1D(),\n",
    "            layers.Dropout(0.1),\n",
    "            layers.Conv1D(16, kernel_size=7, strides=1),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu'),\n",
    "            layers.MaxPool1D(),\n",
    "            layers.Dropout(0.1),\n",
    "            layers.Conv1D(32, kernel_size=7, strides=1),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu'),\n",
    "            layers.MaxPool1D(),\n",
    "            layers.Dropout(0.1),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation=\"relu\"),\n",
    "        ],\n",
    "        name=\"encoder\",\n",
    "    )\n",
    "\n",
    "def build_projection_head():\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            layers.Input((64,)),\n",
    "            layers.Dense(32, activation=\"relu\"),\n",
    "        ],\n",
    "        name=\"projection_head\",\n",
    "    )\n",
    "\n",
    "def build_classification_head():\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            layers.Input((64,)),\n",
    "            layers.Dense(1, activation=\"relu\"),\n",
    "        ],\n",
    "        name=\"classification_head\",\n",
    "    )\n",
    "# build_encoder().summary()\n",
    "\n",
    "# keras.Sequential([build_encoder(), build_projection_head()]).summary()\n",
    "# keras.Sequential([build_encoder(), build_classification_head()]).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1c722d68-f049-456d-9e5c-841e6a38fcb2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_augmenter(stddev=0.1):\n",
    "    return keras.Sequential([\n",
    "        layers.GaussianNoise(stddev),\n",
    "        # LowPassFilterDeterministic()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "28a046a3-37e3-4094-b8d7-2fffd5592dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">234</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_48          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">234</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">234</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_49          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,616</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_50          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,216</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_48 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m234\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_48          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m234\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │            \u001b[38;5;34m16\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_48 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m234\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_48 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m117\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_48 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m117\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_49 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │           \u001b[38;5;34m464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_49          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_49 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_49 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_49 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_50 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m3,616\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_50          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_50 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_50 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_50 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_16 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,216\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,536</span> (209.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m53,536\u001b[0m (209.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,432</span> (208.72 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m53,432\u001b[0m (208.72 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> (416.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m104\u001b[0m (416.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"projection_head\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"projection_head\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> (8.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,080\u001b[0m (8.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> (8.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,080\u001b[0m (8.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"classification_head\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"classification_head\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> (260.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m65\u001b[0m (260.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> (260.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m65\u001b[0m (260.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - c_acc: 0.0156 - c_loss: 114.4446 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.6970 - val_p_acc: 0.8525\n",
      "Epoch 2/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 24.0976 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.7149 - val_p_acc: 0.8525\n",
      "Epoch 3/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 14.1829 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.7739 - val_p_acc: 0.8484\n",
      "Epoch 4/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 26.0709 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.7557 - val_p_acc: 0.8484\n",
      "Epoch 5/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 13.5484 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.7509 - val_p_acc: 0.8443\n",
      "Epoch 6/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 17.6304 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.8558 - val_p_acc: 0.6680\n",
      "Epoch 7/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 60.1052 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.7238 - val_p_acc: 0.8525\n",
      "Epoch 8/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 11.0990 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.7483 - val_p_acc: 0.8607\n",
      "Epoch 9/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 19.2209 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.7172 - val_p_acc: 0.8484\n",
      "Epoch 10/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 14.2798 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.7240 - val_p_acc: 0.8484\n",
      "Epoch 11/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 11.1536 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.7140 - val_p_acc: 0.8525\n",
      "Epoch 12/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 33.5464 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.6972 - val_p_acc: 0.8443\n",
      "Epoch 13/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 4.4349 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.6945 - val_p_acc: 0.8525\n",
      "Epoch 14/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 6.0705 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.6945 - val_p_acc: 0.8525\n",
      "Epoch 15/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 5.7088 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.6940 - val_p_acc: 0.8525\n",
      "Epoch 16/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 3.4940 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.6939 - val_p_acc: 0.8525\n",
      "Epoch 17/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 2.2048 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.6941 - val_p_acc: 0.8525\n",
      "Epoch 18/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 1.7433 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.6942 - val_p_acc: 0.8525\n",
      "Epoch 19/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 2.7879 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.6942 - val_p_acc: 0.8525\n",
      "Epoch 20/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 5.6989 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.6945 - val_p_acc: 0.8525\n",
      "Epoch 21/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 2.8151 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.6941 - val_p_acc: 0.8525\n",
      "Epoch 22/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - c_acc: 0.0156 - c_loss: 1.1076 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.6940 - val_p_acc: 0.8525\n",
      "Epoch 23/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - c_acc: 0.0156 - c_loss: 1.4232 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.6939 - val_p_acc: 0.8525\n",
      "Epoch 24/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 1.2470 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.6939 - val_p_acc: 0.8525\n",
      "Epoch 25/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 0.8426 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.6939 - val_p_acc: 0.8525\n",
      "Epoch 26/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 0.9046 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.6939 - val_p_acc: 0.8525\n",
      "Epoch 27/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 0.6931 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.6939 - val_p_acc: 0.8525\n",
      "Epoch 28/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 0.8231 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.6939 - val_p_acc: 0.8525\n",
      "Epoch 29/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 0.7820 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.6939 - val_p_acc: 0.8525\n",
      "Epoch 30/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - c_acc: 0.0156 - c_loss: 0.7425 - p_acc: 0.0000e+00 - p_loss: 0.0000e+00 - val_p_loss: 0.6939 - val_p_acc: 0.8525\n",
      "Maximal validation accuracy: 86.07%\n"
     ]
    }
   ],
   "source": [
    "class ContrastiveModel(keras.Model):\n",
    "    def __init__(self, temperature=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.temperature = temperature\n",
    "        self.contrastive_augmenter = get_augmenter(0.5)\n",
    "        self.classification_augmenter = get_augmenter(0.1)\n",
    "        self.encoder = build_encoder()\n",
    "        # Non-linear MLP as projection head\n",
    "        self.projection_head = build_projection_head()\n",
    "        # Single dense layer for linear probing\n",
    "        self.linear_probe = build_classification_head()\n",
    "\n",
    "        self.encoder.summary()\n",
    "        self.projection_head.summary()\n",
    "        self.linear_probe.summary()\n",
    "\n",
    "    def compile(self, contrastive_optimizer, probe_optimizer, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "\n",
    "        self.contrastive_optimizer = contrastive_optimizer\n",
    "        self.probe_optimizer = probe_optimizer\n",
    "\n",
    "        # self.contrastive_loss will be defined as a method\n",
    "        self.probe_loss = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "        self.contrastive_loss_tracker = keras.metrics.Mean(name=\"c_loss\")\n",
    "        self.contrastive_accuracy = keras.metrics.BinaryAccuracy(name=\"c_acc\")\n",
    "        self.probe_loss_tracker = keras.metrics.Mean(name=\"p_loss\")\n",
    "        self.probe_accuracy = keras.metrics.BinaryAccuracy(name=\"p_acc\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.contrastive_loss_tracker,\n",
    "            self.contrastive_accuracy,\n",
    "            self.probe_loss_tracker,\n",
    "            self.probe_accuracy,\n",
    "        ]\n",
    "\n",
    "    def contrastive_loss(self, projections_1, projections_2):\n",
    "        # InfoNCE loss (information noise-contrastive estimation)\n",
    "        # NT-Xent loss (normalized temperature-scaled cross entropy)\n",
    "        # print(projections_1.shape, projections_2.shape)\n",
    "        # Cosine similarity: the dot product of the l2-normalized feature vectors\n",
    "        projections_1 = ops.normalize(projections_1, axis=-1)\n",
    "        projections_2 = ops.normalize(projections_2, axis=-1)\n",
    "        # print(projections_1.shape, projections_2.shape)\n",
    "        # similarities = (\n",
    "        #     ops.matmul(projections_1, ops.transpose(projections_2)) / self.temperature\n",
    "        # )\n",
    "        similarities = (\n",
    "            keras.losses.cosine_similarity(projections_1, projections_2) / self.temperature\n",
    "        )\n",
    "        # The similarity between the representations of two augmented views of the\n",
    "        # same image should be higher than their similarity with other views\n",
    "        batch_size = tf.shape(projections_1)[0]\n",
    "        contrastive_labels = ops.arange(batch_size)\n",
    "        # print(contrastive_labels.shape, similarities.shape)\n",
    "        # print(contrastive_labels, similarities, self.contrastive_accuracy.update_state([1], [[0.1,0.9]]))\n",
    "        self.contrastive_accuracy.update_state(contrastive_labels, similarities)\n",
    "        self.contrastive_accuracy.update_state(contrastive_labels, ops.transpose(similarities))\n",
    "\n",
    "        # The temperature-scaled similarities are used as logits for cross-entropy\n",
    "        # a symmetrized version of the loss is used here\n",
    "        loss_1_2 = keras.losses.binary_crossentropy(\n",
    "            contrastive_labels, similarities, from_logits=True\n",
    "        )\n",
    "        loss_2_1 = keras.losses.binary_crossentropy(\n",
    "            contrastive_labels, ops.transpose(similarities), from_logits=True\n",
    "        )\n",
    "        return (loss_1_2 + loss_2_1) / 2\n",
    "\n",
    "    def train_step(self, data):\n",
    "        images = data\n",
    "\n",
    "        # Both labeled and unlabeled images are used, without labels\n",
    "        # images = ops.concatenate((unlabeled_images, labeled_images), axis=0)\n",
    "        # print(images.shape)\n",
    "        # Each image is augmented twice, differently\n",
    "        augmented_images_1 = self.contrastive_augmenter(images, training=True)\n",
    "        augmented_images_2 = self.contrastive_augmenter(images, training=True)\n",
    "        with tf.GradientTape() as tape:\n",
    "            features_1 = self.encoder(augmented_images_1, training=True)\n",
    "            features_2 = self.encoder(augmented_images_2, training=True)\n",
    "            # The representations are passed through a projection mlp\n",
    "            projections_1 = self.projection_head(features_1, training=True)\n",
    "            projections_2 = self.projection_head(features_2, training=True)\n",
    "            contrastive_loss = self.contrastive_loss(projections_1, projections_2)\n",
    "        gradients = tape.gradient(\n",
    "            contrastive_loss,\n",
    "            self.encoder.trainable_weights + self.projection_head.trainable_weights,\n",
    "        )\n",
    "        self.contrastive_optimizer.apply_gradients(\n",
    "            zip(\n",
    "                gradients,\n",
    "                self.encoder.trainable_weights + self.projection_head.trainable_weights,\n",
    "            )\n",
    "        )\n",
    "        self.contrastive_loss_tracker.update_state(contrastive_loss)\n",
    "\n",
    "        # Labels are only used in evalutation for an on-the-fly logistic regression\n",
    "        # preprocessed_images = self.classification_augmenter(\n",
    "        #     labeled_images, training=True\n",
    "        # )\n",
    "        # with tf.GradientTape() as tape:\n",
    "        #     # the encoder is used in inference mode here to avoid regularization\n",
    "        #     # and updating the batch normalization paramers if they are used\n",
    "        #     features = self.encoder(preprocessed_images, training=False)\n",
    "        #     class_logits = self.linear_probe(features, training=True)\n",
    "        #     probe_loss = self.probe_loss(labels, class_logits)\n",
    "        # gradients = tape.gradient(probe_loss, self.linear_probe.trainable_weights)\n",
    "        # self.probe_optimizer.apply_gradients(\n",
    "        #     zip(gradients, self.linear_probe.trainable_weights)\n",
    "        # )\n",
    "        # self.probe_loss_tracker.update_state(probe_loss)\n",
    "        # self.probe_accuracy.update_state(labels, class_logits)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        labeled_images, labels = data\n",
    "\n",
    "        # For testing the components are used with a training=False flag\n",
    "        preprocessed_images = self.classification_augmenter(\n",
    "            labeled_images, training=False\n",
    "        )\n",
    "        features = self.encoder(preprocessed_images, training=False)\n",
    "        class_logits = self.linear_probe(features, training=False)\n",
    "        probe_loss = self.probe_loss(labels, class_logits)\n",
    "        self.probe_loss_tracker.update_state(probe_loss)\n",
    "        self.probe_accuracy.update_state(labels, class_logits)\n",
    "\n",
    "        # Only the probe metrics are logged at test time\n",
    "        return {m.name: m.result() for m in self.metrics[2:]}\n",
    "\n",
    "\n",
    "# Contrastive pretraining\n",
    "pretraining_model = ContrastiveModel()\n",
    "pretraining_model.compile(\n",
    "    contrastive_optimizer=keras.optimizers.Adam(),\n",
    "    probe_optimizer=keras.optimizers.Adam(),\n",
    ")\n",
    "\n",
    "pretraining_history = pretraining_model.fit(\n",
    "    unlabeled_train_ds, epochs=30, validation_data=test_ds\n",
    ")\n",
    "print(\n",
    "    \"Maximal validation accuracy: {:.2f}%\".format(\n",
    "        max(pretraining_history.history[\"val_p_acc\"]) * 100\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "491753b9-85dd-448f-b0f2-916cc9d158b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 0.8147 - loss: 0.7245 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 2/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 3/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 4/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 5/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 6/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 7/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 8/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 9/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 10/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 11/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 12/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 13/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 14/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 15/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 16/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 17/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 18/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 19/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 20/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 21/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 22/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 23/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 24/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 25/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 26/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 27/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 28/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 29/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Epoch 30/30\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8654 - loss: 0.6931 - val_binary_accuracy: 0.8525 - val_loss: 0.6931\n",
      "Maximal validation accuracy: 85.25%\n"
     ]
    }
   ],
   "source": [
    "sl_model = keras.Sequential([build_encoder(), build_classification_head()])\n",
    "sl_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[\n",
    "        keras.metrics.BinaryAccuracy(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "sl_history = sl_model.fit(\n",
    "    labeled_train_ds, epochs=30, validation_data=test_ds\n",
    ")\n",
    "print(\n",
    "    \"Maximal validation accuracy: {:.2f}%\".format(\n",
    "        max(sl_history.history[\"val_binary_accuracy\"]) * 100\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "deb0ad33-d111-46c8-8b4f-659aad55e8b6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from sys import exit\n",
    "from functools import lru_cache\n",
    "\n",
    "import neurokit2 as nk\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.fft import fft, ifft\n",
    "from scipy.signal import iirnotch, iirpeak, filtfilt\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "class GaussianNoiseDeterministic:\n",
    "    def __init__(self, sigma_scale=0.1):\n",
    "        \"\"\"\n",
    "        :param sigma_scale: factor to use in computing sigma parameter for noise distribution\n",
    "            sigma = mean(abs(diff between signal & mean))) * sigma_scale\n",
    "        \"\"\"\n",
    "        self.sigma_scale = sigma_scale\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        mean_power_diff = np.mean(np.abs(x - np.mean(x)))\n",
    "        noise_sigma = mean_power_diff * self.sigma_scale\n",
    "        noise = np.random.normal(scale=noise_sigma, size=len(x))\n",
    "        return x + noise\n",
    "\n",
    "\n",
    "class GaussianNoiseStochastic:\n",
    "    def __init__(self, sigma_scale_min=0.0, sigma_scale_max=0.5):\n",
    "        \"\"\"\n",
    "        :param sigma_scale_min: min factor to use in computing sigma parameter for noise distribution\n",
    "        :param sigma_scale_max: max factor to use in computing sigma parameter for noise distribution\n",
    "            sample sigma_scale uniformly in [sigma_scale_min, sigma_scale_max)\n",
    "            sigma = mean(abs(diff between signal & mean))) * sigma_scale\n",
    "        \"\"\"\n",
    "        self.sigma_scale_min = sigma_scale_min\n",
    "        self.sigma_scale_max = sigma_scale_max\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        # sample sigma scale\n",
    "        sigma_scale = np.random.uniform(self.sigma_scale_min, self.sigma_scale_max)\n",
    "        mean_power_diff = np.mean(np.abs(x - np.mean(x)))\n",
    "        noise_sigma = mean_power_diff * sigma_scale\n",
    "        noise = np.random.normal(scale=noise_sigma, size=len(x))\n",
    "        return x + noise\n",
    "\n",
    "\n",
    "class Identity:\n",
    "    def __call__(self, sample_dict):\n",
    "        return sample_dict['x']\n",
    "\n",
    "\n",
    "class LowPassFilterDeterministic(layers.Layer):\n",
    "    def __init__(self, data_freq=4, highcut_hz=0.05, **kwargs):\n",
    "        \"\"\"\n",
    "        Apply low pass filter to remove frequency bands >= highcut_hz\n",
    "        :param data_freq: frequency of data to apply filter to (e.g., 4Hz for EDA)\n",
    "        :param highcut_hz: lower bound on frequency bands to remove\n",
    "        \"\"\"\n",
    "        super(LowPassFilterDeterministic, self).__init__(**kwargs)\n",
    "        self.data_freq = data_freq\n",
    "        self.highcut_hz = highcut_hz\n",
    "        self.b, self.a = scipy.signal.butter(4, [highcut_hz], btype=\"lowpass\", output=\"ba\", fs=data_freq)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        print(inputs)\n",
    "        segment_filtered = scipy.signal.filtfilt(self.b, self.a, inputs, axis=1)\n",
    "        return segment_filtered\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def memoize_scipy_lowpass_butter_design_ba(order, highcut_hz, fs):\n",
    "    b, a = scipy.signal.butter(order, [highcut_hz], btype=\"lowpass\", output=\"ba\", fs=fs)\n",
    "    return b, a\n",
    "\n",
    "\n",
    "class LowPassFilterStochastic:\n",
    "    def __init__(self, data_freq=4, highcut_hz_min=0.01, highcut_hz_max=1, n_steps=1000):\n",
    "        \"\"\"\n",
    "        Apply low pass filter to remove frequency bands >= highcut_hz\n",
    "        :param data_freq: frequency of data to apply filter to (e.g., 4Hz for EDA)\n",
    "        :param highcut_hz_min: min cutoff freq to use\n",
    "        :param highcut_hz_max: max cutoff freq to use (sample from [min, max))\n",
    "        \"\"\"\n",
    "        self.data_freq = data_freq\n",
    "        self.highcut_hz_min = highcut_hz_min\n",
    "        self.highcut_hz_max = highcut_hz_max\n",
    "        self.n_steps = n_steps\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        # discretise the space so we get some speed benefits \n",
    "        highcut_hz = np.random.choice(np.linspace(self.highcut_hz_min, self.highcut_hz_max, self.n_steps))\n",
    "        b, a = memoize_scipy_lowpass_butter_design_ba(\n",
    "            order=4, highcut_hz=highcut_hz, fs=self.data_freq,\n",
    "        )\n",
    "        segment_filtered = scipy.signal.filtfilt(b, a, x)\n",
    "        return segment_filtered\n",
    "\n",
    "\n",
    "class HighPassFilterDeterministic:\n",
    "    def __init__(self, data_freq=4, lowcut_hz=0.05):\n",
    "        \"\"\"\n",
    "        Apply high pass filter to remove frequency bands <= lowcut_hz\n",
    "        :param data_freq: frequency of data to apply filter to (e.g., 4Hz for EDA)\n",
    "        :param lowcut_hz: upper bound on frequency bands to remove\n",
    "        \"\"\"\n",
    "        self.data_freq = data_freq\n",
    "        self.lowcut_hz = lowcut_hz\n",
    "        self.b, self.a = scipy.signal.butter(4, [lowcut_hz], btype=\"highpass\", output=\"ba\", fs=data_freq)\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        segment_filtered = scipy.signal.filtfilt(self.b, self.a, x)\n",
    "        return segment_filtered\n",
    "    \n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def memoize_scipy_highpass_butter_design_ba(order, lowcut_hz, fs):\n",
    "    b, a = scipy.signal.butter(order, [lowcut_hz], btype=\"highpass\", output=\"ba\", fs=fs)\n",
    "    return b, a\n",
    "\n",
    "\n",
    "class HighPassFilterStochastic:\n",
    "    def __init__(self, data_freq=4, lowcut_hz_min=0.01, lowcut_hz_max=1, n_steps=1000):\n",
    "        \"\"\"\n",
    "        Apply high pass filter to remove frequency bands <= lowcut_hz\n",
    "        :param data_freq: frequency of data to apply filter to (e.g., 4Hz for EDA)\n",
    "        :param lowcut_hz: upper bound on frequency bands to remove\n",
    "        \"\"\"\n",
    "        self.data_freq = data_freq\n",
    "        self.lowcut_hz_min = lowcut_hz_min\n",
    "        self.lowcut_hz_max = lowcut_hz_max\n",
    "        self.n_steps = n_steps\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        lowcut_hz = np.random.choice(np.linspace(self.lowcut_hz_min, self.lowcut_hz_max, self.n_steps))\n",
    "        b, a = memoize_scipy_highpass_butter_design_ba(\n",
    "            order=4, lowcut_hz=lowcut_hz, fs=self.data_freq,\n",
    "        )\n",
    "        segment_filtered = scipy.signal.filtfilt(b, a, x)\n",
    "        return segment_filtered\n",
    "\n",
    "\n",
    "class HighFrequencyNoiseDeterministic:\n",
    "    def __init__(self, sigma_scale=0.1, freq_bin_start_idx=60, freq_bin_stop_idx=120):\n",
    "        self.sigma_scale = sigma_scale\n",
    "        self.freq_bin_start_idx = freq_bin_start_idx\n",
    "        self.req_bin_stop_idx = freq_bin_stop_idx\n",
    "        self.freq_bin_idxs = np.arange(freq_bin_start_idx, freq_bin_stop_idx)\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        x_fft = fft(x)\n",
    "        mean_fft_val = np.mean(np.abs(x_fft))\n",
    "        sigma = self.sigma_scale * mean_fft_val\n",
    "        noise = np.random.normal(scale=sigma, size=len(self.freq_bin_idxs))\n",
    "        x_fft[self.freq_bin_idxs] += noise\n",
    "        # get the corresponding negative bins\n",
    "        neg_end_idx = len(x) + 1 - self.freq_bin_start_idx\n",
    "        neg_start_idx = neg_end_idx - len(self.freq_bin_idxs)\n",
    "        x_fft[neg_start_idx:neg_end_idx] += np.flip(noise)\n",
    "        x_ifft = np.abs(ifft(x_fft))\n",
    "        return x_ifft\n",
    "\n",
    "\n",
    "class HighFrequencyNoiseStochastic:\n",
    "    def __init__(self, sigma_scale_min=0.0, sigma_scale_max=1.0, freq_bin_start_idx=60, freq_bin_stop_idx=120):\n",
    "        self.sigma_scale_min = sigma_scale_min\n",
    "        self.sigma_scale_max = sigma_scale_max\n",
    "        self.freq_bin_start_idx = freq_bin_start_idx\n",
    "        self.req_bin_stop_idx = freq_bin_stop_idx\n",
    "        self.freq_bin_idxs = np.arange(freq_bin_start_idx, freq_bin_stop_idx)\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        x_fft = fft(x)\n",
    "        mean_fft_val = np.mean(np.abs(x_fft))\n",
    "        # sample sigma scale\n",
    "        sigma_scale = np.random.uniform(self.sigma_scale_min, self.sigma_scale_max)\n",
    "        sigma = sigma_scale * mean_fft_val\n",
    "        noise = np.random.normal(scale=sigma, size=len(self.freq_bin_idxs))\n",
    "        x_fft[self.freq_bin_idxs] += noise\n",
    "        # get the corresponding negative bins\n",
    "        neg_end_idx = len(x) + 1 - self.freq_bin_start_idx\n",
    "        neg_start_idx = neg_end_idx - len(self.freq_bin_idxs)\n",
    "        x_fft[neg_start_idx:neg_end_idx] += np.flip(noise)\n",
    "        x_ifft = np.abs(ifft(x_fft))\n",
    "        return x_ifft\n",
    "\n",
    "\n",
    "class BandstopFilterDeterministic:\n",
    "    def __init__(self, data_freq=4, remove_freq=0.25, Q=0.707):\n",
    "        \"\"\"\n",
    "        Selects frequency band to remove.\n",
    "        See https://stackoverflow.com/questions/54320638/how-to-create-a-bandstop-filter-in-python\n",
    "        :param data_freq: frequency of data to apply filter to (e.g., 4Hz for EDA)\n",
    "        :param remove_freq: frequency band to remove\n",
    "        :param Q: \"quality factor\" Q = remove_freq / width of filter\n",
    "        see - https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.iirnotch.html\n",
    "        and https://en.wikipedia.org/wiki/Q_factor\n",
    "        \"\"\"\n",
    "        self.data_freq = data_freq\n",
    "        self.remove_freq = remove_freq\n",
    "        self.Q = Q\n",
    "        self.b, self.a = iirnotch(self.remove_freq, self.Q, fs=self.data_freq)\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        return filtfilt(self.b, self.a, x)\n",
    "\n",
    "\n",
    "class BandstopFilterStochastic:\n",
    "    def __init__(self, data_freq=4, remove_freq_min=0.01, remove_freq_max=1.0, Q=0.707):\n",
    "        \"\"\"\n",
    "        Randomly selects frequency band to remove.\n",
    "        See https://stackoverflow.com/questions/54320638/how-to-create-a-bandstop-filter-in-python\n",
    "        :param data_freq: frequency of data to apply filter to (e.g., 4Hz for EDA)\n",
    "        :param remove_freq_min: minimum frequency band to remove\n",
    "        :param remove_freq_max: maximum frequency band to remove (sample remove_freq from uniform [min, max))\n",
    "        :param Q: \"quality factor\" Q = remove_freq / width of filter\n",
    "        see - https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.iirnotch.html\n",
    "        and https://en.wikipedia.org/wiki/Q_factor\n",
    "        \"\"\"\n",
    "        self.data_freq = data_freq\n",
    "        self.remove_feq_min = remove_freq_min\n",
    "        self.remove_freq_max = remove_freq_max\n",
    "        self.Q = Q\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        # sample frequency band to remove\n",
    "        remove_freq = np.random.uniform(self.remove_feq_min, self.remove_freq_max)\n",
    "        b, a = iirnotch(remove_freq, self.Q, fs=self.data_freq)\n",
    "        return filtfilt(b, a, x)\n",
    "\n",
    "\n",
    "class BandpassFilterDeterministic:\n",
    "    def __init__(self, data_freq=4, keep_freq=0.25, Q=0.707):\n",
    "        \"\"\"\n",
    "        Select frequency band to keep\n",
    "        :param keep_freq: central frequency to keep\n",
    "        :param Q: \"quality factor\" Q = width of filter\n",
    "        \"\"\"\n",
    "        self.data_freq = data_freq\n",
    "        self.keep_freq = keep_freq\n",
    "        self.Q = Q\n",
    "        self.b, self.a = iirpeak(self.keep_freq, self.Q, fs=self.data_freq)\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        return filtfilt(self.b, self.a, x)\n",
    "    \n",
    "\n",
    "class BandpassFilterStochastic:\n",
    "    def __init__(self, data_freq=4, keep_freq_min=0.01, keep_freq_max=1, Q=0.707):\n",
    "        \"\"\"\n",
    "        Randomly selects frequency band to keep\n",
    "        :param keep_freq_min: min central frequency to keep\n",
    "        :param keep_freq_max: max central frequency to keep\n",
    "        :param Q: \"quality factor\" Q = width of filter\n",
    "        \"\"\"\n",
    "        self.data_freq = data_freq\n",
    "        self.keep_freq_min = keep_freq_min\n",
    "        self.keep_freq_max = keep_freq_max\n",
    "        self.Q = Q\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        keep_freq = np.random.uniform(self.keep_freq_min, self.keep_freq_max)\n",
    "        b, a = iirpeak(keep_freq, self.Q, fs=self.data_freq)\n",
    "        return filtfilt(b, a, x)\n",
    "\n",
    "\n",
    "class TemporalCutoutDeterministic:\n",
    "    \"\"\" Cutouts / Masks a section of the signal window \"\"\"\n",
    "    def __init__(self, cutout_size=100):\n",
    "        self.cutout_size = cutout_size\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        # randomly sample cutout start\n",
    "        start_min = 0\n",
    "        start_max = len(x) - self.cutout_size\n",
    "        cutout_start = np.random.choice(np.arange(start_min, start_max))\n",
    "        x_trf = copy.deepcopy(x)\n",
    "        x_trf[cutout_start:cutout_start+self.cutout_size] = 0\n",
    "        return x_trf\n",
    "\n",
    "\n",
    "class TemporalCutoutStochastic:\n",
    "    \"\"\" Cutouts / Masks a section of the signal window \"\"\"\n",
    "    def __init__(self, cutout_size_min=1, cutout_size_max=120):\n",
    "        self.cutout_size_min = cutout_size_min\n",
    "        self.cutout_size_max = cutout_size_max\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        cutout_size = np.random.choice(np.arange(self.cutout_size_min, self.cutout_size_max+1))\n",
    "        start_min = 0\n",
    "        start_max = len(x) - cutout_size\n",
    "        cutout_start = np.random.choice(np.arange(start_min, start_max+1))\n",
    "        x_trf = copy.deepcopy(x)\n",
    "        x_trf[cutout_start:cutout_start+cutout_size] = 0\n",
    "        return x_trf\n",
    "\n",
    "\n",
    "class PermuteDeterministic:\n",
    "    \"\"\" Splits segments into chunks and permutes them \"\"\"\n",
    "    def __init__(self, n_splits=10):\n",
    "        self.n_splits = n_splits\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        orig_steps = np.arange(x.shape[0])\n",
    "        splits = np.array_split(orig_steps, self.n_splits)\n",
    "        np.random.shuffle(splits)\n",
    "        warp_idx = np.concatenate(splits)\n",
    "        x_warped = x[warp_idx]\n",
    "        return x_warped\n",
    "\n",
    "\n",
    "class PermuteStochastic:\n",
    "    \"\"\" Splits segments into chunks and permutes them \"\"\"\n",
    "    def __init__(self, n_splits_max=10):\n",
    "        self.n_splits_max = n_splits_max\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        orig_steps = np.arange(x.shape[0])\n",
    "        num_splits = np.random.randint(2, self.n_splits_max)\n",
    "        splits = np.array_split(orig_steps, num_splits)\n",
    "        np.random.shuffle(splits)\n",
    "        warp_idx = np.concatenate(splits)\n",
    "        x_warped = x[warp_idx]\n",
    "        return x_warped\n",
    "\n",
    "\n",
    "class Flip:\n",
    "    \"\"\" Flips segments around horizontal axis \"\"\"\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        flip = -1\n",
    "        x_flip = flip * x + (2 * np.mean(x))\n",
    "        return x_flip\n",
    "\n",
    "\n",
    "class TimeShiftDeterministic:\n",
    "    \"\"\" Shifts the window left or right by a number of samples \"\"\"\n",
    "    def __init__(self, shift_len=120):\n",
    "        self.shift_len = shift_len\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        # compose x with left and right buffer\n",
    "        left_buffer = sample_dict['x_left_buffer']\n",
    "        right_buffer = sample_dict['x_right_buffer']\n",
    "        # drop nans from left and right buffer segment['x_left_buffer']\n",
    "        left_buffer = left_buffer[~np.isnan(left_buffer)]\n",
    "        right_buffer = right_buffer[~np.isnan(right_buffer)]\n",
    "        x = sample_dict['x']\n",
    "        signal = np.concatenate([left_buffer, x, right_buffer])\n",
    "        # sample shift to apply --- make sure not out-of-bounds!!\n",
    "        left_shift_len = min(self.shift_len, len(left_buffer))\n",
    "        right_shift_len = min(self.shift_len, len(right_buffer))\n",
    "        shift = np.random.choice([-left_shift_len, right_shift_len])  # choose whether to shift left or right in time\n",
    "        start_index = len(left_buffer) + shift\n",
    "        x_trf = signal[start_index:start_index+len(x)]\n",
    "        return x_trf\n",
    "\n",
    "\n",
    "class TimeShiftStochastic:\n",
    "    \"\"\" Shifts the window left or right by a number of samples \"\"\"\n",
    "    def __init__(self, shift_len_min=120, shift_len_max=240):\n",
    "        self.shift_min = shift_len_min\n",
    "        self.shift_max = shift_len_max\n",
    "        self.shift_lens = np.arange(self.shift_min, self.shift_max, 1)\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        # compose x with left and right buffer\n",
    "        left_buffer = sample_dict['x_left_buffer']\n",
    "        right_buffer = sample_dict['x_right_buffer']\n",
    "        # drop nans from left and right buffer segment['x_left_buffer']\n",
    "        left_buffer = left_buffer[~np.isnan(left_buffer)]\n",
    "        right_buffer = right_buffer[~np.isnan(right_buffer)]\n",
    "        x = sample_dict['x']\n",
    "        signal = np.concatenate([left_buffer, x, right_buffer])\n",
    "        # sample shift len to apply\n",
    "        shift_len = np.random.choice(self.shift_lens)\n",
    "        # adjust so shift is in bounds & sample whether to apply it on left or right\n",
    "        left_shift_len = min(shift_len, len(left_buffer))\n",
    "        right_shift_len = min(shift_len, len(right_buffer))\n",
    "        shift = np.random.choice([-left_shift_len, right_shift_len])  # choose whether to shift left or right in time\n",
    "        start_index = len(left_buffer) + shift\n",
    "        x_trf = signal[start_index:start_index+len(x)]\n",
    "        return x_trf\n",
    "\n",
    "\n",
    "class TimeWarpingDeterministic:\n",
    "    \"\"\" \n",
    "    Warps the signal across time by creating a spline, warping time, \n",
    "    and then interpolating the signal back to the orignal time steps.\n",
    "    See: https://arxiv.org/pdf/2007.15951.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma=0.25, knot=4):\n",
    "        self.sigma = sigma\n",
    "        self.knot = knot\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        \n",
    "        orig_steps = np.arange(x.shape[0])\n",
    "\n",
    "        random_warps = np.random.normal(loc=1.0, scale=self.sigma, size=(self.knot+2))\n",
    "        warp_steps = (np.linspace(0, x.shape[0]-1, num=self.knot+2)).T\n",
    "\n",
    "        # warps time to != 240\n",
    "        time_warp = CubicSpline(warp_steps, warp_steps * random_warps)(orig_steps)  \n",
    "        # scales the warping back to the window length\n",
    "        scale = (x.shape[0]-1)/time_warp[-1]  \n",
    "        # using the warped time steps and the original signal, linearly interpolate back onto the original time steps \n",
    "        x_time_warped = np.interp(orig_steps, np.clip(scale*time_warp, 0, x.shape[0]-1), x).T\n",
    "        \n",
    "        return x_time_warped\n",
    "    \n",
    "\n",
    "class TimeWarpingStochastic:\n",
    "    \"\"\" \n",
    "    Warps the signal across time by creating a spline, warping time, \n",
    "    and then interpolating the signal back to the orignal time steps.\n",
    "    See: https://arxiv.org/pdf/2007.15951.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma_min=0.01, sigma_max=0.25, knot_min=1, knot_max=4):\n",
    "        self.sigma_min = sigma_min\n",
    "        self.sigma_max = sigma_max\n",
    "        self.knot_min = knot_min\n",
    "        self.knot_max = knot_max\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        \n",
    "        sigma = np.random.uniform(self.sigma_min, self.sigma_max)\n",
    "        knot = np.random.choice(np.arange(self.knot_min, self.knot_max+1))\n",
    "\n",
    "        orig_steps = np.arange(x.shape[0])\n",
    "        random_warps = np.random.normal(loc=1.0, scale=sigma, size=(knot+2))\n",
    "        warp_steps = (np.linspace(0, x.shape[0]-1, num=knot+2)).T\n",
    "\n",
    "        # warps time to != 240\n",
    "        time_warp = CubicSpline(warp_steps, warp_steps * random_warps)(orig_steps)  \n",
    "        # scales the warping back to the window length\n",
    "        scale = (x.shape[0]-1)/time_warp[-1]  \n",
    "        # using the warped time steps and the original signal, linearly interpolate back onto the original time steps \n",
    "        x_time_warped = np.interp(orig_steps, np.clip(scale*time_warp, 0, x.shape[0]-1), x).T\n",
    "        \n",
    "        return x_time_warped\n",
    "\n",
    "\n",
    "class ExtractComponent:\n",
    "    def __init__(self, component, method=\"highpass\"):\n",
    "        self.component = component\n",
    "        self.method = method\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        print(\"method\", self.method)\n",
    "        x = sample_dict['x']\n",
    "        decomposed = nk.eda_phasic(x, sampling_rate=4, method=self.method)\n",
    "        return decomposed[f\"EDA_{self.component}\"].to_numpy()\n",
    "\n",
    "\n",
    "class ExtractPhasic(ExtractComponent):\n",
    "    def __init__(self, method=\"highpass\"):\n",
    "        print(\"extract phasic\")\n",
    "        super().__init__(\"Phasic\", method)\n",
    "\n",
    "\n",
    "class ExtractTonic(ExtractComponent):\n",
    "    def __init__(self, method=\"highpass\"):\n",
    "        print(\"extract tonic\")\n",
    "        super().__init__(\"Tonic\", method)\n",
    "\n",
    "\n",
    "class LooseSensorArtifactDeterministic:\n",
    "    def __init__(self, width=4, smooth_width_min=2, smooth_width_max=80):\n",
    "        self.width = width\n",
    "        self.smooth_width_min = smooth_width_min\n",
    "        self.smooth_width_max = smooth_width_max\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        \n",
    "        # sample width of artifact\n",
    "        artifact_width = self.width\n",
    "        # sample artifact start\n",
    "        artifact_start = np.random.choice(np.arange(0, len(x) - artifact_width + 1))\n",
    "        # compute artifact end (inclusive)\n",
    "        artifact_end = artifact_start + artifact_width - 1\n",
    "        \n",
    "        # don't smooth if artifact goes all the way to boundary\n",
    "        smooth_left = (artifact_start != 0)\n",
    "        smooth_right = (artifact_end != len(x) - 1)\n",
    "        \n",
    "        # sample smoothing edge widths\n",
    "        smooth_max = min(self.smooth_width_max, int(artifact_width/2))\n",
    "        smooth_width1 = np.random.choice(np.arange(self.smooth_width_min, smooth_max + 1)) if smooth_left else 0\n",
    "        smooth_width2 = np.random.choice(np.arange(self.smooth_width_min, smooth_max + 1)) if smooth_right else 0\n",
    "        \n",
    "        # add drop to non-smoothed regions of artifact\n",
    "        noisy_segment = copy.deepcopy(x)\n",
    "        drop_start = artifact_start + smooth_width1\n",
    "        drop_end = artifact_end - smooth_width2  # (inclusive)\n",
    "        # get mean amplitude of signal in this range\n",
    "        mean_amp = np.mean(noisy_segment[drop_start:drop_end + 1])  # +1 so inclusive\n",
    "        # subtract from signal\n",
    "        noisy_segment[drop_start:drop_end + 1] -= mean_amp\n",
    "        # zero out negative entries\n",
    "        noisy_segment[noisy_segment < 0] = 0\n",
    "        \n",
    "        # fill in parts to be smoothed\n",
    "        # fit cubic spline\n",
    "        # get pre-smooth, unsmoothed artifact, post-smooth\n",
    "        train_x = np.concatenate([\n",
    "            np.arange(artifact_start),  # don't include artifact start\n",
    "            np.arange(drop_start, drop_end + 1),  # include drop end\n",
    "            np.arange(artifact_end + 1, len(x)) # don't include artifact end\n",
    "        ])\n",
    "        train_y = np.concatenate([\n",
    "            noisy_segment[:artifact_start],\n",
    "            noisy_segment[drop_start:drop_end + 1],\n",
    "            noisy_segment[artifact_end + 1:]\n",
    "        ])\n",
    "        spline = CubicSpline(train_x, train_y)\n",
    "        # fill in smoothed parts\n",
    "        if artifact_start != drop_start:\n",
    "            noisy_segment[artifact_start:drop_start] = spline(np.arange(artifact_start, drop_start))\n",
    "        if artifact_end != drop_end:\n",
    "            noisy_segment[drop_end + 1:artifact_end + 1] = spline(np.arange(drop_end + 1, artifact_end + 1))  # include artifact end\n",
    "        return noisy_segment\n",
    "\n",
    "\n",
    "class LooseSensorArtifactStochastic:\n",
    "    def __init__(self, width_min=4, width_max=120, smooth_width_min=2, smooth_width_max=20):\n",
    "        self.width_min = width_min\n",
    "        self.width_max = width_max\n",
    "        self.smooth_width_min = smooth_width_min\n",
    "        self.smooth_width_max = smooth_width_max\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        \n",
    "        # sample width of artifact\n",
    "        artifact_width = np.random.choice(np.arange(self.width_min, self.width_max + 1))  # +1 so its inclusive\n",
    "\n",
    "        # sample artifact start\n",
    "        artifact_start = np.random.choice(np.arange(0, len(x) - artifact_width + 1))\n",
    "        # compute artifact end (inclusive)\n",
    "        artifact_end = artifact_start + artifact_width - 1\n",
    "        \n",
    "        # don't smooth if artifact goes all the way to boundary\n",
    "        smooth_left = (artifact_start != 0)\n",
    "        smooth_right = (artifact_end != len(x) - 1)\n",
    "        \n",
    "        # sample smoothing edge widths\n",
    "        smooth_available = int((artifact_width-2)/2)  # need to leave at least 2 dropped out samples\n",
    "        smooth_max = min(self.smooth_width_max, smooth_available)\n",
    "        smooth_min = min(smooth_max, self.smooth_width_min)\n",
    "        smooth_width1 = np.random.choice(np.arange(smooth_min, smooth_max + 1)) if smooth_left else 0\n",
    "        smooth_width2 = np.random.choice(np.arange(smooth_min, smooth_max + 1)) if smooth_right else 0\n",
    "        \n",
    "        # add drop to non-smoothed regions of artifact\n",
    "        noisy_segment = copy.deepcopy(x)\n",
    "        drop_start = artifact_start + smooth_width1\n",
    "        drop_end = artifact_end - smooth_width2  # (inclusive)\n",
    "        # get mean amplitude of signal in this range\n",
    "        mean_amp = np.mean(noisy_segment[drop_start:drop_end + 1])  # +1 so inclusive\n",
    "        # subtract from signal\n",
    "        noisy_segment[drop_start:drop_end + 1] -= mean_amp\n",
    "        # zero out negative entries\n",
    "        noisy_segment[noisy_segment < 0] = 0\n",
    "        \n",
    "        # fill in parts to be smoothed\n",
    "        # fit cubic spline\n",
    "        # get pre-smooth, unsmoothed artifact, post-smooth\n",
    "        train_x = np.concatenate([\n",
    "            np.arange(artifact_start),  # don't include artifact start\n",
    "            np.arange(drop_start, drop_end + 1),  # include drop end\n",
    "            np.arange(artifact_end + 1, len(x)) # don't include artifact end\n",
    "        ])\n",
    "        train_y = np.concatenate([\n",
    "            noisy_segment[:artifact_start],\n",
    "            noisy_segment[drop_start:drop_end + 1],\n",
    "            noisy_segment[artifact_end + 1:]\n",
    "        ])\n",
    "        spline = CubicSpline(train_x, train_y)\n",
    "        # fill in smoothed parts\n",
    "        if artifact_start != drop_start:\n",
    "            noisy_segment[artifact_start:drop_start] = spline(np.arange(artifact_start, drop_start))\n",
    "        if artifact_end != drop_end:\n",
    "            noisy_segment[drop_end + 1:artifact_end + 1] = spline(np.arange(drop_end + 1, artifact_end + 1))  # include artifact end\n",
    "        return noisy_segment\n",
    "\n",
    "\n",
    "class JumpArtifactDeterministic:\n",
    "    def __init__(self, max_n_jumps=2, shift_factor=0.1, smooth_width_min=2, smooth_width_max=12):\n",
    "        self.max_n_jumps = max_n_jumps\n",
    "        self.shift_factor = shift_factor\n",
    "        self.smooth_width_min = smooth_width_min\n",
    "        self.smooth_width_max = smooth_width_max\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        noisy_segment = copy.deepcopy(x)\n",
    "        \n",
    "        # time flip so we can apply the logic below in either direction\n",
    "        time_flip = np.random.choice([-1, 1]) \n",
    "        if time_flip == -1:\n",
    "            noisy_segment = np.flip(noisy_segment)\n",
    "        \n",
    "        # sample n artifacts\n",
    "        n_jumps = np.random.choice(np.arange(1, self.max_n_jumps + 1)) # make inclusive\n",
    "        \n",
    "        # sample artifact starts and shift factors\n",
    "        min_start = 1 # don't start at 0 because this would shift whole segment instead of creating jump\n",
    "        # needs to start early enough that there is enough room to smooth jump (with smallest smoothing window)\n",
    "        max_start = len(x) - self.smooth_width_min - 2 \n",
    "        artifact_starts = np.sort(np.random.choice(np.arange(min_start, max_start + 1), size=n_jumps, replace=False))\n",
    "        artifact_shift_factors = self.shift_factor * np.random.choice([-1, 1], size=n_jumps)\n",
    "        \n",
    "        # loop through & apply shifts\n",
    "        for idx, a_start in enumerate(artifact_starts):\n",
    "            # sample smoothing window (how many samples to smooth)\n",
    "            # smooth window needs to fit in between a_start and end of x with at least a one sample gap\n",
    "            _smooth_max = min(self.smooth_width_max, len(x) - a_start - 2)\n",
    "            a_smooth_win = np.random.choice(np.arange(self.smooth_width_min, _smooth_max + 1)) # make inclusive\n",
    "            x_post_smooth = noisy_segment[a_start + a_smooth_win:]\n",
    "            # add jump to x_post_smooth, scale it by width of smooth window (want to control jump/sec)\n",
    "            x_post_smooth += artifact_shift_factors[idx] * (a_smooth_win / 4)  # get smooth win in secs\n",
    "            \n",
    "            # fill in parts to be smoothed\n",
    "            # fit cubic spline\n",
    "            # get pre-smooth, unsmoothed artifact, post-smooth\n",
    "            train_x = np.concatenate([\n",
    "                np.arange(a_start),  # everywhere but where smoothing occurs\n",
    "                np.arange(a_start + a_smooth_win, len(x))\n",
    "            ])\n",
    "            train_y = np.concatenate([\n",
    "                noisy_segment[:a_start],\n",
    "                noisy_segment[a_start + a_smooth_win:],\n",
    "            ])\n",
    "            spline = CubicSpline(train_x, train_y)\n",
    "            # fill in smoothed parts\n",
    "            noisy_segment[a_start:a_start + a_smooth_win] = spline(np.arange(a_start, a_start + a_smooth_win))\n",
    "            \n",
    "            # zero out negative entries\n",
    "            noisy_segment[noisy_segment < 0] = 0\n",
    "            \n",
    "        # Flip the segment back to original time order if it was reversed\n",
    "        if time_flip == -1:\n",
    "            noisy_segment = np.flip(noisy_segment)\n",
    "        \n",
    "        return noisy_segment\n",
    "    \n",
    "\n",
    "class JumpArtifactStochastic:\n",
    "    def __init__(self, max_n_jumps=2, shift_factor_min=0.01, shift_factor_max=0.2, smooth_width_min=2, smooth_width_max=12):\n",
    "        self.max_n_jumps = max_n_jumps\n",
    "        self.shift_factor_min = shift_factor_min\n",
    "        self.shift_factor_max = shift_factor_max\n",
    "        self.smooth_width_min = smooth_width_min\n",
    "        self.smooth_width_max = smooth_width_max\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        noisy_segment = copy.deepcopy(x)\n",
    "        \n",
    "        # time flip so we can apply the logic below in either direction\n",
    "        time_flip = np.random.choice([-1, 1]) \n",
    "        if time_flip == -1:\n",
    "            noisy_segment = np.flip(noisy_segment)\n",
    "        \n",
    "        # sample n artifacts\n",
    "        n_jumps = np.random.choice(np.arange(1, self.max_n_jumps + 1)) # make inclusive\n",
    "        \n",
    "        # sample artifact starts and shift factors\n",
    "        min_start = 1 # don't start at 0 because this would shift whole segment instead of creating jump\n",
    "        # needs to start early enough that there is enough room to smooth jump (with smallest smoothing window)\n",
    "        max_start = len(x) - self.smooth_width_min - 2 \n",
    "        artifact_starts = np.sort(np.random.choice(np.arange(min_start, max_start + 1), size=n_jumps, replace=False))\n",
    "        artifact_shift_factors = np.random.uniform(low=self.shift_factor_min, high=self.shift_factor_max, size=n_jumps) * np.random.choice([-1, 1], size=n_jumps)\n",
    "        \n",
    "        # loop through & apply shifts\n",
    "        for idx, a_start in enumerate(artifact_starts):\n",
    "            # sample smoothing window (how many samples to smooth)\n",
    "            # smooth window needs to fit in between a_start and end of x with at least a one sample gap\n",
    "            _smooth_max = min(self.smooth_width_max, len(x) - a_start - 2)\n",
    "            a_smooth_win = np.random.choice(np.arange(self.smooth_width_min, _smooth_max + 1)) # make inclusive\n",
    "            x_pre_artifact = noisy_segment[:a_start]\n",
    "            x_smooth_win = noisy_segment[a_start:a_start + a_smooth_win]\n",
    "            x_post_smooth = noisy_segment[a_start + a_smooth_win:]\n",
    "            # add jump to x_post_smooth, scale it by width of smooth window (want to control jump/sec)\n",
    "            x_post_smooth += artifact_shift_factors[idx] * (a_smooth_win / 4)  # get smooth win in secs\n",
    "            \n",
    "            # fill in parts to be smoothed\n",
    "            # fit cubic spline\n",
    "            # get pre-smooth, unsmoothed artifact, post-smooth\n",
    "            train_x = np.concatenate([\n",
    "                np.arange(a_start),  # everywhere but where smoothing occurs\n",
    "                np.arange(a_start + a_smooth_win, len(x))\n",
    "            ])\n",
    "            train_y = np.concatenate([\n",
    "                noisy_segment[:a_start],\n",
    "                noisy_segment[a_start + a_smooth_win:],\n",
    "            ])\n",
    "            spline = CubicSpline(train_x, train_y)\n",
    "            # fill in smoothed parts\n",
    "            noisy_segment[a_start:a_start + a_smooth_win] = spline(np.arange(a_start, a_start + a_smooth_win))\n",
    "            \n",
    "            # zero out negative entries\n",
    "            noisy_segment[noisy_segment < 0] = 0\n",
    "            \n",
    "        # Flip the segment back to original time order if it was reversed\n",
    "        if time_flip == -1:\n",
    "            noisy_segment = np.flip(noisy_segment)\n",
    "\n",
    "        return noisy_segment\n",
    "\n",
    "\n",
    "class ConstantAmplitudeScalingDeterministic:\n",
    "    \"\"\" Scale EDA by constant factor across the window \"\"\"\n",
    "    def __init__(self, scale=1):\n",
    "        self.scale = scale\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        return x * self.scale\n",
    "    \n",
    "    \n",
    "class ConstantAmplitudeScalingStochastic:\n",
    "    \"\"\" Scale EDA by constant factor across the window \"\"\"\n",
    "    def __init__(self, scale_min=0.5, scale_max=1.5):\n",
    "        self.scale_min = scale_min\n",
    "        self.scale_max = scale_max\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        scale = np.random.uniform(self.scale_min, self.scale_max)\n",
    "        return x * scale\n",
    "\n",
    "\n",
    "class AmplitudeWarpingDeterministic:\n",
    "    \"\"\" \n",
    "    Scale EDA by a smoothly varying factor across the window \n",
    "    Note: if knot = 0 then scale factor changes linearly\n",
    "    See: https://arxiv.org/pdf/2007.15951.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma=0.2, knot=4):\n",
    "        self.sigma = sigma\n",
    "        self.knot = knot\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        \n",
    "        orig_steps = np.arange(x.shape[0])\n",
    "        random_warps = np.random.normal(loc=1.0, scale=self.sigma, size=(self.knot+2))\n",
    "        warp_steps = (np.linspace(0, x.shape[0]-1, num=self.knot+2)).T\n",
    "\n",
    "        warper = CubicSpline(warp_steps, random_warps)(orig_steps)        \n",
    "\n",
    "        return x * warper\n",
    "    \n",
    "\n",
    "class AmplitudeWarpingStochastic:\n",
    "    \"\"\" \n",
    "    Scale EDA by a smoothly varying factor across the window \n",
    "    Note: if knot = 0 then scale factor changes linearly\n",
    "    See: https://arxiv.org/pdf/2007.15951.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma_min=0.01, sigma_max=0.25, knot_min=0, knot_max=4):\n",
    "        self.sigma_min = sigma_min\n",
    "        self.sigma_max = sigma_max\n",
    "        self.knot_min = knot_min\n",
    "        self.knot_max = knot_max\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        \n",
    "        sigma = np.random.uniform(self.sigma_min, self.sigma_max)\n",
    "        knot = np.random.choice(np.arange(self.knot_min, self.knot_max+1))\n",
    "\n",
    "        orig_steps = np.arange(x.shape[0])\n",
    "        random_warps = np.random.normal(loc=1.0, scale=sigma, size=(knot+2))\n",
    "        warp_steps = (np.linspace(0, x.shape[0]-1, num=knot+2)).T\n",
    "\n",
    "        warper = CubicSpline(warp_steps, random_warps)(orig_steps)        \n",
    "\n",
    "        return x * warper\n",
    "\n",
    "\n",
    "class TonicConstantAmplitudeScalingDeterministic:\n",
    "    \"\"\"\n",
    "    Mimics the effect of temperature / humidity on the EDA signal with a CONSTANT scale factor on tonic\n",
    "    See: Qasim, Masood S., Dindar S. Bari, and Ørjan G. Martinsen. \n",
    "    “Influence of ambient temperature on tonic and phasic electrodermal activity components.” \n",
    "    Physiological Measurement 43.6 (2022): 065001.\n",
    "    And: Bari, D. S., Aldosky, H. Y. Y., Tronstad, C., Kalvøy, H., & Martinsen, Ø. G. (2018). \n",
    "    \"Influence of relative humidity on electrodermal levels and responses.\" \n",
    "    Skin pharmacology and physiology, 31(6), 298-307.\n",
    "    \"\"\"\n",
    "    def __init__(self, tonic_scale_factor, data_freq=4):\n",
    "        self.tonic_scale_factor = tonic_scale_factor\n",
    "        # design the filters to extract tonic and phasic\n",
    "        self.data_freq = data_freq\n",
    "        self.b_tonic, self.a_tonic = scipy.signal.butter(4, [0.05], btype=\"lowpass\", output=\"ba\", fs=data_freq) \n",
    "        self.b_phasic, self.a_phasic = scipy.signal.butter(4, [0.05], btype=\"highpass\", output=\"ba\", fs=data_freq) \n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        \n",
    "        x = sample_dict['x']\n",
    "        tonic = scipy.signal.filtfilt(self.b_tonic, self.a_tonic, x)\n",
    "        phasic = scipy.signal.filtfilt(self.b_phasic, self.a_phasic, x)\n",
    "        tonic_scaled = tonic * self.tonic_scale_factor\n",
    "        \n",
    "        return tonic_scaled + phasic\n",
    "    \n",
    "    \n",
    "class TonicConstantAmplitudeScalingStochastic:\n",
    "    \"\"\"\n",
    "    Mimics the effect of temperature / humidity on the EDA signal with a CONSTANT scale factor on tonic\n",
    "    See: Qasim, Masood S., Dindar S. Bari, and Ørjan G. Martinsen. \n",
    "    “Influence of ambient temperature on tonic and phasic electrodermal activity components.” \n",
    "    Physiological Measurement 43.6 (2022): 065001.\n",
    "    And: Bari, D. S., Aldosky, H. Y. Y., Tronstad, C., Kalvøy, H., & Martinsen, Ø. G. (2018). \n",
    "    \"Influence of relative humidity on electrodermal levels and responses.\" \n",
    "    Skin pharmacology and physiology, 31(6), 298-307.\n",
    "    \"\"\"\n",
    "    def __init__(self, tonic_scale_factor_min=0.5, tonic_scale_factor_max=1.5, data_freq=4):\n",
    "        self.tonic_scale_factor_min = tonic_scale_factor_min\n",
    "        self.tonic_scale_factor_max = tonic_scale_factor_max\n",
    "        # design the filters to extract tonic and phasic. Note: it's OK for these to be in constructor as they're constant\n",
    "        self.data_freq = data_freq\n",
    "        self.b_tonic, self.a_tonic = scipy.signal.butter(4, [0.05], btype=\"lowpass\", output=\"ba\", fs=data_freq) \n",
    "        self.b_phasic, self.a_phasic = scipy.signal.butter(4, [0.05], btype=\"highpass\", output=\"ba\", fs=data_freq) \n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        \n",
    "        tonic_scale_factor = np.random.uniform(self.tonic_scale_factor_min, self.tonic_scale_factor_max)\n",
    "        \n",
    "        tonic = scipy.signal.filtfilt(self.b_tonic, self.a_tonic, x)\n",
    "        phasic = scipy.signal.filtfilt(self.b_phasic, self.a_phasic, x)\n",
    "        tonic_scaled = tonic * tonic_scale_factor\n",
    "        \n",
    "        return tonic_scaled + phasic\n",
    "\n",
    "\n",
    "class TonicAmplitudeWarpingDeterministic:\n",
    "    \"\"\"\n",
    "    Mimics the effect of temperature / humidity on the EDA signal with a SMOOTH time-varying scale factor on tonic\n",
    "    See: Qasim, Masood S., Dindar S. Bari, and Ørjan G. Martinsen. \n",
    "    “Influence of ambient temperature on tonic and phasic electrodermal activity components.” \n",
    "    Physiological Measurement 43.6 (2022): 065001.\n",
    "    And: Bari, D. S., Aldosky, H. Y. Y., Tronstad, C., Kalvøy, H., & Martinsen, Ø. G. (2018). \n",
    "    \"Influence of relative humidity on electrodermal levels and responses.\" \n",
    "    Skin pharmacology and physiology, 31(6), 298-307.\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma=0.1, knot=4, data_freq=4):\n",
    "        self.sigma = sigma\n",
    "        self.knot = knot\n",
    "        # design the filters to extract tonic and phasic\n",
    "        self.data_freq = data_freq\n",
    "        self.b_tonic, self.a_tonic = scipy.signal.butter(4, [0.05], btype=\"lowpass\", output=\"ba\", fs=data_freq) \n",
    "        self.b_phasic, self.a_phasic = scipy.signal.butter(4, [0.05], btype=\"highpass\", output=\"ba\", fs=data_freq) \n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        \n",
    "        x = sample_dict['x']\n",
    "        \n",
    "        tonic = scipy.signal.filtfilt(self.b_tonic, self.a_tonic, x)\n",
    "        phasic = scipy.signal.filtfilt(self.b_phasic, self.a_phasic, x)\n",
    "        \n",
    "        orig_steps = np.arange(tonic.shape[0])\n",
    "        random_warps = np.random.normal(loc=1.0, scale=self.sigma, size=(self.knot+2))\n",
    "        warp_steps = (np.linspace(0, x.shape[0]-1, num=self.knot+2)).T\n",
    "        warper = CubicSpline(warp_steps, random_warps)(orig_steps)\n",
    "        tonic_warped = tonic * warper\n",
    "        \n",
    "        return tonic_warped + phasic\n",
    "    \n",
    "    \n",
    "class TonicAmplitudeWarpingStochastic:\n",
    "    \"\"\"\n",
    "    Mimics the effect of temperature / humidity on the EDA signal with a SMOOTH time-varying scale factor on tonic\n",
    "    See: Qasim, Masood S., Dindar S. Bari, and Ørjan G. Martinsen. \n",
    "    “Influence of ambient temperature on tonic and phasic electrodermal activity components.” \n",
    "    Physiological Measurement 43.6 (2022): 065001.\n",
    "    And: Bari, D. S., Aldosky, H. Y. Y., Tronstad, C., Kalvøy, H., & Martinsen, Ø. G. (2018). \n",
    "    \"Influence of relative humidity on electrodermal levels and responses.\" \n",
    "    Skin pharmacology and physiology, 31(6), 298-307.\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma_min=0.01, sigma_max=0.25, knot_min=0, knot_max=4, data_freq=4):\n",
    "        self.sigma_min = sigma_min\n",
    "        self.sigma_max = sigma_max\n",
    "        self.knot_min = knot_min\n",
    "        self.knot_max = knot_max\n",
    "        # design the filters to extract tonic and phasic. Note: it's OK for these to be in constructor as they're constant\n",
    "        self.data_freq = data_freq\n",
    "        self.b_tonic, self.a_tonic = scipy.signal.butter(4, [0.05], btype=\"lowpass\", output=\"ba\", fs=data_freq) \n",
    "        self.b_phasic, self.a_phasic = scipy.signal.butter(4, [0.05], btype=\"highpass\", output=\"ba\", fs=data_freq) \n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        \n",
    "        sigma = np.random.uniform(self.sigma_min, self.sigma_max)\n",
    "        knot = np.random.choice(np.arange(self.knot_min, self.knot_max+1))\n",
    "\n",
    "        tonic = scipy.signal.filtfilt(self.b_tonic, self.a_tonic, x)\n",
    "        phasic = scipy.signal.filtfilt(self.b_phasic, self.a_phasic, x)\n",
    "        \n",
    "        orig_steps = np.arange(tonic.shape[0])\n",
    "        random_warps = np.random.normal(loc=1.0, scale=sigma, size=(knot+2))\n",
    "        warp_steps = (np.linspace(0, x.shape[0]-1, num=knot+2)).T\n",
    "        warper = CubicSpline(warp_steps, random_warps)(orig_steps)\n",
    "        tonic_warped = tonic * warper\n",
    "        \n",
    "        return tonic_warped + phasic\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Deprecated below this line \n",
    "\"\"\"\n",
    "\n",
    "class FlipWrist:\n",
    "    def __call__(self, sample_dict):\n",
    "        x_opp_wrist = sample_dict['x_opp_wrist']\n",
    "        return x_opp_wrist\n",
    "\n",
    "\n",
    "class ScalePhasic:\n",
    "    def __init__(self, scale_factor_max=2, scale_step=0.1):\n",
    "        self.scale_factors = np.arange(1 / scale_factor_max, scale_factor_max + scale_step, scale_step)\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        # randomly sample scaling factor\n",
    "        scale = np.random.choice(self.scale_factors)\n",
    "        decomp = nk.eda_phasic(x, sampling_rate=4, method='highpass')\n",
    "        phasic = decomp[\"EDA_Phasic\"].to_numpy()\n",
    "        phasic_scaled = phasic * scale\n",
    "        return decomp[\"EDA_Tonic\"].to_numpy() + phasic_scaled\n",
    "\n",
    "\n",
    "class DCShift:\n",
    "    def __init__(self, shift_factor_max=2, shift_step=0.1):\n",
    "        self.shift_factors = np.arange(-shift_factor_max, shift_factor_max, shift_step)\n",
    "\n",
    "    def __call__(self, sample_dict):\n",
    "        x = sample_dict['x']\n",
    "        # randomly sample shift\n",
    "        shift_factor = np.random.choice(self.shift_factors)\n",
    "        mean_power_diff = np.mean(np.abs(x - np.mean(x)))\n",
    "        shift = shift_factor * mean_power_diff\n",
    "        return x + shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663c60a5-37dd-49f9-987c-980dc613b99f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
